{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/\n",
    "\n",
    "https://www.cdc.gov/dengue/\n",
    "\n",
    "### Goal\n",
    "\n",
    "Predict the number of dengue cases each week (in each location) based on environmental variables describing changes in temperature, precipitation, vegetation, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql.functions import abs \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"dengue\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"data/\"\n",
    "\n",
    "\n",
    "features_train = spark.read.csv(path_to_data + \"dengue_features_train.csv\", header=True)\n",
    "#df_features['month'] = df_features['week_start_date'][5:7]\n",
    "\n",
    "labels_train = spark.read.csv(path_to_data + \"dengue_labels_train.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description des données\n",
    "\n",
    "Your goal is to predict the total_cases label for each (`city`, `year`, `weekofyear`) in the test set. \n",
    "There are two cities, *San Juan* and *Iquitos*, with test data for each city spanning 5 and 3 years respectively.\n",
    "You will make one submission that contains predictions for both cities.\n",
    "The data for each city have been concatenated along with a city column indicating the source: `sj` for San Juan and `iq` for Iquitos. \n",
    "The test set is a pure future hold-out, meaning the test data are sequential and non-overlapping with any of the training data.\n",
    "Throughout, missing values have been filled as `NaN`s.\n",
    "\n",
    "#### The features in this dataset\n",
    "\n",
    "You are provided the following set of information on a (`year`, `weekofyear`) timescale:\n",
    "\n",
    "(Where appropriate, units are provided as a `_unit` suffix on the feature name.)\n",
    "\n",
    "*City and date indicators*\n",
    "\n",
    " - `city` – City abbreviations: `sj` for San Juan and `iq` for Iquitos\n",
    " - `week_start_date` – Date given in yyyy-mm-dd format\n",
    "\n",
    "*NOAA's GHCN daily climate data weather station measurements*\n",
    "\n",
    " - `station_max_temp_c` – Maximum temperature\n",
    " - `station_min_temp_c` – Minimum temperature\n",
    " - `station_avg_temp_c` – Average temperature\n",
    " - `station_precip_mm` – Total precipitation\n",
    " - `station_diur_temp_rng_c` – Diurnal temperature range\n",
    " \n",
    "*PERSIANN satellite precipitation measurements (0.25x0.25 degree scale)*\n",
    "\n",
    " - `precipitation_amt_mm` – Total precipitation\n",
    "\n",
    "*NOAA's NCEP Climate Forecast System Reanalysis measurements (0.5x0.5 degree scale)*\n",
    "\n",
    " - `reanalysis_sat_precip_amt_mm` – Total precipitation\n",
    " - `reanalysis_dew_point_temp_k` – Mean dew point temperature\n",
    " - `reanalysis_air_temp_k` – Mean air temperature\n",
    " - `reanalysis_relative_humidity_percent` – Mean relative humidity\n",
    " - `reanalysis_specific_humidity_g_per_kg` – Mean specific humidity\n",
    " - `reanalysis_precip_amt_kg_per_m2` – Total precipitation\n",
    " - `reanalysis_max_air_temp_k` – Maximum air temperature\n",
    " - `reanalysis_min_air_temp_k` – Minimum air temperature\n",
    " - `reanalysis_avg_temp_k` – Average air temperature\n",
    " - `reanalysis_tdtr_k` – Diurnal temperature range\n",
    "\n",
    "*Satellite vegetation - Normalized difference vegetation index (NDVI) - NOAA's CDR Normalized Difference Vegetation Index (0.5x0.5 degree scale) measurements*\n",
    "\n",
    " - `ndvi_se` – Pixel southeast of city centroid\n",
    " - `ndvi_sw` – Pixel southwest of city centroid\n",
    " - `ndvi_ne` – Pixel northeast of city centroid\n",
    " - `ndvi_nw` – Pixel northwest of city centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"features_train = ({}, {})\".format(features_train.count(), len(features_train.columns)))\n",
    "\n",
    "features_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"labels_train = ({}, {})\".format(labels_train.count(), len(labels_train.columns)))\n",
    "\n",
    "labels_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We join the 2 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = features_train.join(labels_train, ['city', 'year', 'weekofyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_train = ({}, {})\".format(df_train.count(), len(df_train.columns)))\n",
    "\n",
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select('year', 'weekofyear', 'week_start_date', 'precipitation_amt_mm', 'reanalysis_sat_precip_amt_mm').show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df_train.drop('precipitation_amt_mm', 'week_start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in df_train.columns:\n",
    "    if col_name not in ['city', 'week_start_date']:\n",
    "        df_train = df_train.withColumn(col_name, df_train[col_name].cast('float'))\n",
    "\n",
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"size of the data: {}\".format(df_train.shape()))\n",
    "\n",
    "df_train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='city',\n",
    "                        outputCol='city_')\n",
    "\n",
    "df_train = indexer.fit(df_train).transform(df_train)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol='city_', outputCol='cityVect')\n",
    "df_train = encoder.transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new feature characterizing the \"surface\" of the city (in pixels) defined by:\n",
    "\n",
    "city_surface_px = |ndvi_ne - ndvi_sw| x |ndvi_nw - ndvi_se|\n",
    "\n",
    "Small `city_surface_px` means a lot of vegetation (and maybe a lot of mosquitos!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn('city_surface_px', abs(df_train.ndvi_ne - df_train.ndvi_sw) * abs(df_train.ndvi_nw - df_train.ndvi_se))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select('city_surface_px').show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_features = ['year', 'weekofyear', 'precipitation_amt_mm',\n",
    "#               'ndvi_ne', 'ndvi_nw', 'ndvi_se', 'ndvi_sw',\n",
    "               'city_surface_px',\n",
    "               'reanalysis_air_temp_k','reanalysis_avg_temp_k',\n",
    "               'reanalysis_dew_point_temp_k', 'reanalysis_max_air_temp_k',\n",
    "               'reanalysis_min_air_temp_k', 'reanalysis_precip_amt_kg_per_m2',\n",
    "               'reanalysis_relative_humidity_percent', 'reanalysis_sat_precip_amt_mm', \n",
    "               'reanalysis_specific_humidity_g_per_kg', 'reanalysis_tdtr_k',\n",
    "               'station_avg_temp_c','station_diur_temp_rng_c',\n",
    "               'station_max_temp_c', 'station_min_temp_c',\n",
    "               'station_precip_mm', 'cityVect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=lr_features, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_vectorised = vectorAssembler.transform(df_train)\n",
    "df_train_vectorised.select('features').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol='features', outputCol=\"scaled_features\",\n",
    "                        withStd=True, withMean=True)\n",
    "\n",
    "scaler_model = scaler.fit(df_train_vectorised)\n",
    "\n",
    "df_train = scaler_model.transform(df_train_vectorised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_train.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='scaled_features',\n",
    "                      labelCol='total_cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = model_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr.select(['total_cases','prediction']).show(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = model_lr.summary.rootMeanSquaredError\n",
    "r2 = model_lr.summary.r2\n",
    "\n",
    "print(\"rmse = {:.3f} / r2 = {:.3f}\".format(rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol='total_cases',\n",
    "                                predictionCol='prediction',\n",
    "                                metricName='mae')\n",
    "\n",
    "mae_lr = evaluator.evaluate(pred_lr)\n",
    "\n",
    "print(\"mae = {:.3f}\".format(mae_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol='scaled_features', labelCol='total_cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = model_rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_rf = evaluator.evaluate(pred_rf)\n",
    "\n",
    "print(\"mae = {:.3f}\".format(mae_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
